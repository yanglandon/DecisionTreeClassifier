# DecisionTreeClassifier
- Nodes are split based on information gain, which is defined by the reduction in entropy.
- Stopping criterion: When the information gain drops below a certain threshold, splitting stops. 
- Sample data is randomly split into training and testing data, run through the model, and compared to the pre-coded version in the scikit-learn library.
