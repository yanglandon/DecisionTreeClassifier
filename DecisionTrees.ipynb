{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "yqYMVLmcoYox"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from collections import Counter, deque\n",
        "from numbers import Number\n",
        "\n",
        "from sklearn.datasets import load_wine\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def _entropy(y):\n",
        "    # https://en.wikipedia.org/wiki/Entropy_(information_theory)\n",
        "    result = 0\n",
        "    for category, count in Counter(y).items():\n",
        "        probability = count / len(y)\n",
        "        result -= probability * math.log(probability, 2)\n",
        "    return result\n",
        "\n",
        "\n",
        "def _info_gain(x, y, x_is_continuous):\n",
        "    # https://machinelearningmastery.com/information-gain-and-mutual-information/\n",
        "    starting_entropy = _entropy(y)\n",
        "    n = len(x)\n",
        "    tuples = sorted([(x_i, y_i) for x_i, y_i in zip(x, y)], key=lambda tup: tup[0])\n",
        "    sorted_x, sorted_y = [tup[0] for tup in tuples], [tup[1] for tup in tuples]\n",
        "    best_gain, best_split_value = 0, None\n",
        "    for i in range(1, n):\n",
        "        if sorted_x[i] != sorted_x[i - 1]:\n",
        "            entropy_left, entropy_right = _entropy(sorted_y[:i]), _entropy(sorted_y[i:])\n",
        "            gain = starting_entropy - (entropy_left * i / n + entropy_right * (1 - i / n))\n",
        "            if gain >= best_gain:\n",
        "                best_gain = gain\n",
        "                best_split_value = (sorted_x[i - 1] + sorted_x[i]) / 2 if x_is_continuous else x[i - 1]\n",
        "    return best_gain, best_split_value\n",
        "\n",
        "\n",
        "def max_info_gain(X: pd.DataFrame, y: pd.Series):\n",
        "    continuous_columns = set(X.select_dtypes(include=np.number))\n",
        "    best_column, best_gain, best_split_value = None, 0, None\n",
        "    for column in X.columns:\n",
        "        gain, split_value = _info_gain(X[column], y, column in continuous_columns)\n",
        "        if gain > best_gain:\n",
        "            best_column = column\n",
        "            best_gain = gain\n",
        "            best_split_value = split_value\n",
        "    return best_column, best_gain, best_split_value"
      ],
      "metadata": {
        "id": "PcJLhUCkpG_K"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DTNode:\n",
        "    def __init__(self, rows):\n",
        "        self.rows = rows\n",
        "\n",
        "        self.column_name = None\n",
        "        self.is_continuous = None\n",
        "        self.split_val = None\n",
        "        self.left_node = None\n",
        "        self.right_node = None\n",
        "\n",
        "    def split(self, X_train: pd.DataFrame, y_train: pd.Series, info_gain_threshold):\n",
        "        X_train_new, y_train_new = X_train.loc[self.rows], y_train.loc[self.rows]\n",
        "        column_name, info_gain, split_val = max_info_gain(X_train_new, y_train_new)\n",
        "        if info_gain < info_gain_threshold:\n",
        "            return None, None\n",
        "        self.column_name = column_name\n",
        "        self.is_continuous = isinstance(split_val, Number)\n",
        "        self.split_val = split_val\n",
        "        if self.is_continuous:\n",
        "            indices_left = X_train_new.index[X_train_new[column_name] < split_val]\n",
        "            indices_right = X_train_new.index[X_train_new[column_name] >= split_val]\n",
        "        else:\n",
        "            indices_left = X_train_new.index[X_train_new[column_name] == split_val]\n",
        "            indices_right = X_train_new.index[X_train_new[column_name] != split_val]\n",
        "        self.left_node = DTNode(indices_left)\n",
        "        self.right_node = DTNode(indices_right)\n",
        "        return self.left_node, self.right_node\n",
        "\n",
        "\n",
        "class ID3Classifier:\n",
        "    def __init__(self, info_gain_threshold):\n",
        "        self.root = None\n",
        "        self.X_train = None\n",
        "        self.y_train = None\n",
        "        self.info_gain_threshold = info_gain_threshold\n",
        "\n",
        "    def fit(self, X_train: pd.DataFrame, y_train: pd.Series):\n",
        "        self.root = DTNode(X_train.index)\n",
        "        self.X_train = X_train\n",
        "        self.y_train = y_train\n",
        "        queue = deque([self.root])\n",
        "        while len(queue) > 0:\n",
        "            node = queue.popleft()\n",
        "            node.split(X_train, y_train, self.info_gain_threshold)\n",
        "            if node.left_node is not None:\n",
        "                queue.append(node.left_node)\n",
        "            if node.right_node is not None:\n",
        "                queue.append(node.right_node)\n",
        "\n",
        "    def predict(self, X_test: pd.DataFrame):\n",
        "        def _classify_row(row):\n",
        "            curr_node = self.root\n",
        "            while curr_node.left_node is not None and curr_node.right_node is not None:\n",
        "                val = row[curr_node.column_name]\n",
        "                if curr_node.is_continuous:\n",
        "                    curr_node = curr_node.left_node if val < curr_node.split_val else curr_node.right_node\n",
        "                else:\n",
        "                    curr_node = curr_node.left_node if val == curr_node.split_val else curr_node.right_node\n",
        "            items = self.y_train[curr_node.rows].tolist()\n",
        "            return max(items, key=items.count)\n",
        "\n",
        "        return X_test.apply(_classify_row, axis=1)"
      ],
      "metadata": {
        "id": "kXqAI9NApWLb"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X, y = load_wine(return_X_y=True, as_frame=True)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
        "\n",
        "sklearn_model = DecisionTreeClassifier(criterion=\"entropy\")\n",
        "sklearn_model.fit(X_train, y_train)\n",
        "print(\"sklearn accuracy: %.2f\" % sklearn_model.score(X_test, y_test))\n",
        "\n",
        "my_model = ID3Classifier(0.1)\n",
        "my_model.fit(X_train, y_train)\n",
        "print(\"my accuracy: %.2f\" % accuracy_score(y_test, my_model.predict(X_test)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9pw3rRDIpYr_",
        "outputId": "195f5fc6-c32e-49be-d572-177fb979ee77"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sklearn accuracy: 0.96\n",
            "my accuracy: 0.96\n"
          ]
        }
      ]
    }
  ]
}